{"cells":[{"cell_type":"markdown","metadata":{"id":"2VbCO6c5QqN_"},"source":["#Linear Regression"]},{"cell_type":"markdown","metadata":{"id":"OzSY7nEmOUtO"},"source":["Let us implement the Linear Regression from scratch. You may run the cells to visualize the results for yourself."]},{"cell_type":"markdown","metadata":{"id":"9OQhVIZWOh0Z"},"source":["We begin with importing the necessary packages."]},{"cell_type":"code","execution_count":1,"metadata":{"deletable":true,"editable":true,"id":"l-yH_leOQqOG","tags":[]},"outputs":[{"ename":"OSError","evalue":"'seaborn-whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\style\\core.py:137\u001b[0m, in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     style \u001b[38;5;241m=\u001b[39m \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\__init__.py:879\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[1;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[0;32m    878\u001b[0m rc_temp \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 879\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_or_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n","File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\__init__.py:856\u001b[0m, in \u001b[0;36m_open_file_or_url\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    855\u001b[0m fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname)\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn-whitegrid'","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseaborn-whitegrid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\style\\core.py:139\u001b[0m, in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    137\u001b[0m         style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(style)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid package style, path of style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, URL of style file, or library style name (library \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyles are listed in `style.available`)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    143\u001b[0m filtered \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n","\u001b[1;31mOSError\u001b[0m: 'seaborn-whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"]}],"source":["\n","import matplotlib.pyplot as plt\n","import copy\n","import math\n","import seaborn as sns\n","sns.set_style('whitegrid')\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"oYy1TMPPypPI"},"source":["**Regression from Scratch**"]},{"cell_type":"markdown","metadata":{"id":"2nE32wlZPbLG"},"source":["Let us generate our data randomly. We generate x-values using random number generator and obtain y-values using equation y = 2x - 5 + c. Let us also visualise the created data using a scatter plot."]},{"cell_type":"markdown","metadata":{"id":"Czsm4D9DEb2V"},"source":["complete the code:"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":true,"editable":true,"id":"lBT455ouQqOI","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["# fixing the random number generator seed to reproduce the resuts\n","np.random.seed(42)\n","x = np.random.randn(100)\n","y = # create some linear relationship with some randm noise using the equation provided\n","# create a scatter plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJfyAlKbuLZc"},"outputs":[],"source":["x_train, y_train = x , y  # preparing data for training a model."]},{"cell_type":"markdown","metadata":{"id":"PKSSYDdHQUyQ"},"source":["Let us find the data type of x_train variable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ImT7B5WuZCL"},"outputs":[],"source":["# print x_train\n","print(\"Type of x_train:\",type(x_train))\n","print(\"First five elements of x_train are:\\n\", x_train[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKzKmmciud80"},"outputs":[],"source":["# print y_train\n","print(\"Type of y_train:\",type(y_train))\n","print(\"First five elements of y_train are:\\n\", y_train[:5])"]},{"cell_type":"markdown","metadata":{"id":"p0ryW_o1Qmuj"},"source":["Lets us find out the shape of our x and y arrays"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S5rj9xFAuh6I"},"outputs":[],"source":["x_train_shape = # shape of x_train\n","y_train_shape = # shape of y_train\n","print ('The shape of x_train is:', x_train_shape)\n","print ('The shape of y_train is: ', y_train_shape)\n","print ('Number of training examples (m):', len(x_train))"]},{"cell_type":"markdown","metadata":{"id":"N-f88RPX0VRs"},"source":["**Computing the Cost Function**"]},{"cell_type":"markdown","metadata":{"id":"LY5-P2kHRP1z"},"source":["Let us define the cost function to calculate the cost of a predicted output Ypred using the equation y = w*x + b, where (w,b) are variables and x is input.\n","\n","The cost is calculated as : ![CodeCogsEqn (1).png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPAAAAAtBAMAAABi2/tQAAAAMFBMVEX///8AAACYmJhmZmbu7u6qqqpUVFTc3Ny6urp2dnbMzMxERESIiIgyMjIiIiIQEBCcAWo5AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAEyElEQVRYCe1WXWgcVRT+Mjs7szuzu8lE2zTRmI0g9ElWjCLGylQFKRa7gVLw5yHFPxr82YA/YH3YWBVELasFIVKaWVChUHCU2vbJTlrzolFXEP8qskGkVLQuVRBB0HPund9kfUiTbF9yYO/5zjnfPWfunXPvLECijFzzyItvMeqwvDCKz+yXOlyUyzm/4BacvgSF1RbO4qFLUDjtUulWpfOVU17azbjFzhfWKrmyekPn665XXN+B9R1YnR340opJc3VyxrNs/7QcNyM8ZnnCuOPZ+09amyL/aqGSOtA+VcrqCwPXXhHC1QL6URz7n1wLV0WBWf5Q6JG9QuRQsr+whbOoSz9BdasU5k8zfDk0VwoOiwQ/8ZgtL0mWi79ZKqy76uNDDwKpoeNLuID2e8IZoxp2IsJGrkiD8SfDArBt9ENGkbw/ZIcGIbMCg9+1fjb0xsFjcYPShtSuYjLC1lf0yzuM3oVawlS0t+zbYbmsAuH/Xgs2rThwJPXfSTOi1iuLImTuop/8E3kTsjayyVOTsa6MT5kgY7YIjMSdITYWH46Q+kXIiUC3DcXJsN1EoYlMfxRi9LrlxBwtwlsbyLZZAEVyPTEqw5Da7tRoHp5/5gixMiWYTRiX8YxI8lYzMhSXsNmHzaT0N9+en8BzR7fNU8X5m6k3p1/hcFx8aubhwQckMzsNfODzFVe1xH5qDs9RenHkeO70eO5ASaTQrY1CiyFbI5XuT5dJZXPf4T1415emHP1nmFC/xawnWNHgU8HvQDC9SaibIPgwWj6RmprEbKE2WsOvHi5I/7DFZaRoHush3h9sT7XQtbP4hL0P+Rp1m0mN6XAgLpLK70Blpl4eRrpH8qH3+Mx7hB6rGuWTNn4Ezkm/Frs280X27S7x+GS+hK7NNjfyrP3UCMYqmGF/QiQVposMMw26IlMNyYcaXMfiSlAvUPQfgHp5g59iYTDMVRCLv84Wjq4y6lWdD8H5UzuBj4Cv2V84z/KboMCndnvUE8xUN6BQk3zAL6w2mGsWiTIAow+Zy9kmqVtVoWmQK/aTTtn06ArvVz/H/wB6WSfEp0461DzMpGFrVfKh+gWUIk85KKO5Fm+JlGzUXZpHLlXUAT7nJWoueWiHoPbS0xoE4hJQh5GRTK2BKbvKfFofPwlJ3qZB8aAwxRxHt+eQg8QMnoAurBrZaf+KOcabwpuIH+iA0JvJtm4jIy4BdQvulUzKe8goCz6MpqTuZfUqdStTuoqo2x45SG61heJB4fWl/C0axN1V8CbiNeAT7MF9jY/JiEtAvVH1JDPn6mdyki+TEXuOfvq56QMnmFKvYL9eFjmUoPk43kPnd/dGjwP6wEG6NfYzTL9xNXD7vPOonMEuIQEVe+d9JvbM3TUn+dB8doO4BfqL1cfJaA3mKTl7qiq1GL+PsNKK8EUheW/AGG8/W0+06q6IJNoqMpeP/FypavupO0pxv+hA6RBtFY8tF38jJ/gLXzL7TMKjj4fmZDWEFwVyRTltX/vZWjPyjxCktpeSXqBDsRI57E+eaJ9kphL6M+MEF18RYXTZwPFnBDqZIE3fs0DGqgHqgK6XwyJPD4Vw7YHOHz2WO985ZPlXtHSs8cgXSiixG2yNywIz/8bEXfNyYYH/ALrCDeQCXkQ9AAAAAElFTkSuQmCC)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FzNYU7WYu6CA"},"outputs":[],"source":["def compute_cost(x, y, w, b):\n","    m = x.shape[0]                        # number of training examples\n","    total_cost = 0\n","    cost=0\n","    for i in range(m):                    # iteratively calculating the cost for all saz\n","        f_wb =                            # calculate y value\n","        cost +=                           # calculate loss\n","\n","    total_cost = cost/(2*m)               # take final loss to be average of loss of every sample point\n","\n","\n","    return total_cost"]},{"cell_type":"markdown","metadata":{"id":"zt8rJlSgW-xo"},"source":["Let us check out the cost function in action"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8j7cli8nvJUo"},"outputs":[],"source":["# Compute cost with some initial values for paramaters w, b\n","initial_w = 2\n","initial_b = 1\n","\n","cost = # use the above function to compute the cose with these initial w and b\n","print(type(cost))\n","print(f'Cost at initial w (zeros): {cost:.3f}')"]},{"cell_type":"markdown","metadata":{"id":"ZRDY90-f0LMK"},"source":["**Computing the Gradient**"]},{"cell_type":"markdown","metadata":{"id":"XQc5yeINXKHh"},"source":["Let us write a function to compute the gradient (slope) of our cost function along our variables. You must have come across the following equations while looking up the theory of linear regression. Here the red box is the gradients we are calculating now.![download (12).png](data:image/png;base64,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)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7sk0IhGbvPbR"},"outputs":[],"source":["def compute_gradient(x, y, w, b):\n","    # Number of training examples\n","    m = x.shape[0]\n","\n","    dj_dw = 0\n","    dj_db = 0\n","\n","    for i in range(m):\n","        f_wb = w*x[i]+b\n","        dj_db +=  # write these using above function(the red box)\n","        dj_dw +=  # same here\n","    dj_dw /= m\n","    dj_db /= m\n","\n","    return dj_dw, dj_db"]},{"cell_type":"markdown","metadata":{"id":"iFMNLYVCY4ev"},"source":["Let us check out our gradient function in action"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h1aYJmfPvU_j"},"outputs":[],"source":["initial_w = 0\n","initial_b = 0\n","\n","tmp_dj_dw, tmp_dj_db = # use the compute_gradient function to calculate temporary gradients\n","print('Gradient at initial w, b (zeros):', tmp_dj_dw, tmp_dj_db)"]},{"cell_type":"markdown","metadata":{"id":"q6Z3HS8j0DDo"},"source":["**Applying Gradient Descent Algorithm from scratch**"]},{"cell_type":"markdown","metadata":{"id":"MV2esx_FbTC4"},"source":["Coming to the final part of integrating every part of code we have created, Let us implement the gradient descent algorithm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMdTNPN5wQ_4"},"outputs":[],"source":["def gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n","\n","    m = len(x)                                                             # number of training examples\n","    J_history = []                                                         # An array to store cost J and w's at each iteration — primarily for graphing later\n","    w_history = []\n","    w = copy.deepcopy(w_in)                                                # avoid modifying global w within function\n","    b = b_in\n","\n","    for i in range(num_iters):\n","\n","        dj_dw, dj_db = gradient_function(x, y, w, b)                       # Compute gradients\n","\n","        w =                                               # Move along the found gradient direction scaled by alpha / changing the values of w and b based on gradients\n","        b =\n","\n","        cost =                                           # Now find the new cost using the modified variables w, b using function defined before\n","        J_history.append(cost)\n","\n","                                                                           # Print cost after every 10 iterations\n","        if i% math.ceil(num_iters/10) == 0:\n","            w_history.append(w)\n","            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n","\n","    return w, b, J_history, w_history #return w and J,w history for graphing"]},{"cell_type":"markdown","metadata":{"id":"YfQCNDNjc5PX"},"source":["Let us see our implementation in ACTION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q2SnT8f9v9_s"},"outputs":[],"source":["# initialize fitting parameters. Recall that the shape of w is (n,)\n","initial_w = 0.\n","initial_b = 0.\n","\n","# some gradient descent settings\n","iterations = 1500\n","alpha = 0.01\n","\n","w,b,_,_ = gradient_descent(x_train ,y_train, initial_w, initial_b,\n","                     compute_cost, compute_gradient, alpha, iterations)\n","print(\"w,b found by gradient descent:\", w, b)"]},{"cell_type":"markdown","metadata":{"id":"rJnOLTpadQk8"},"source":["Let us see what our regressed equation predicts for every x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s0g_0sMFvfBn"},"outputs":[],"source":["m = x_train.shape[0]\n","predicted = np.zeros(m)\n","\n","for i in range(m):\n","    predicted[i] = w * x_train[i] + b"]},{"cell_type":"markdown","metadata":{"id":"i3_0HJ7pdZu4"},"source":["Visualizing our predictions(points on the straight line) against the actual y values. We see how our algorithm found a good fitting line through our data samples."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L26h-92cvjsO"},"outputs":[],"source":["# Plot the linear fit\n","plt.plot(x_train, predicted)\n","plt.scatter(x_train, y_train)\n","# Set the title\n","# Set the y-axis label\n","# Set the x-axis label\n","plt.show()"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"m1y8dqzzQqOI"},"source":["**Linear Regression Using Scikit-Learn**\n"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"QnJkjNzRQqOJ"},"source":["We can use Scikit-Learn's `LinearRegression` estimator to fit this data and construct the best-fit line, incorporating our previous implementation all in a few lines of code."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":true,"editable":true,"id":"il3IbYdcQqOK","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","model = LinearRegression(fit_intercept=True)\n","\n","model.fit(x[:, np.newaxis], y)                 # This fits the line to the same data we used earlier\n","\n","xfit = np.linspace(0, 10, 1000)\n","yfit = model.predict(xfit[:, np.newaxis])      # This is used to get the predictions\n","\n","plt.scatter(x, y)\n","plt.plot(xfit, yfit);"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"2JRx32UNQqOK"},"source":["The slope and intercept of the data are contained in the model's fit parameters, which in Scikit-Learn are always marked by a trailing underscore.\n","Here the relevant parameters are `coef_` and `intercept_`:"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":true,"editable":true,"id":"7XwJHM-cQqOL","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["print(\"Model slope:    \", model.coef_[0])\n","print(\"Model intercept:\", model.intercept_)"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"XYtSC7TMQqOM"},"source":["We see that the results are very close to the values used to generate the data, as we might hope."]},{"cell_type":"markdown","metadata":{"id":"ES_9sUgCz7TT"},"source":["**Optional-Material**"]},{"cell_type":"markdown","metadata":{"id":"kgncgHzwoned"},"source":["Linear Regression in MultiDimension"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"G1TyhXEoQqOM"},"source":["The `LinearRegression` estimator is much more capable than this, however—in addition to simple straight-line fits, it can also handle multidimensional linear models of the form:\n","$$\n","y = a_0 + a_1 x_1 + a_2 x_2 + \\cdots\n","$$\n","where there are multiple $x$ values.\n","Geometrically, this is akin to fitting a plane to points in three dimensions, or fitting a hyperplane to points in higher dimensions.\n","\n","The multidimensional nature of such regressions makes them more difficult to visualize, but we can see one of these fits in action by building some example data, using NumPy's matrix multiplication operator:"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":true,"editable":true,"id":"i1bpEaLlQqON","jupyter":{"outputs_hidden":false}},"outputs":[],"source":["rng = np.random.RandomState(1)\n","X = 10 * rng.rand(100, 3)\n","y = 0.5 + np.dot(X, [1.5, -2., 1.])\n","\n","model.fit(X, y)\n","print(model.intercept_)\n","print(model.coef_)"]},{"cell_type":"markdown","metadata":{"deletable":true,"editable":true,"id":"MyRm_uYIQqOO"},"source":["Here the $y$ data is constructed from a linear combination of three random $x$ values, and the linear regression recovers the coefficients used to construct the data.\n","\n","In this way, we can use the single `LinearRegression` estimator to fit lines, planes, or hyperplanes to our data.\n","It still appears that this approach would be limited to strictly linear relationships between variables, but it turns out we can relax this as well."]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[{"file_id":"1akKijrpKTaIX6p5akqV1zhaIi1FXHQPq","timestamp":1702467120068},{"file_id":"1wr58u0rGU-ux40ZbCLw8h_iOLLpiMLfn","timestamp":1685398127184},{"file_id":"https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.06-Linear-Regression.ipynb","timestamp":1684856425597}]},"jupytext":{"formats":"ipynb,md"},"kernelspec":{"display_name":"Python 3.9.6 64-bit ('3.9.6')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"vscode":{"interpreter":{"hash":"513788764cd0ec0f97313d5418a13e1ea666d16d72f976a8acadce25a5af2ffc"}}},"nbformat":4,"nbformat_minor":0}
